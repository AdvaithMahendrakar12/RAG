{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209dd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List,Dict, Any\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e3d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madva\\Desktop\\Learning\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b81b9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('data/text_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created successfully.\n"
     ]
    }
   ],
   "source": [
    "sample_text = {\n",
    "    \"data/text_files/machinelearning.txt\": \"\"\"This is a sample text file. It contains multiple sentences. The purpose of this file is to demonstrate text splitting using LangChain's text splitters. We will use different types of text splitters to see how they work.\"\"\",   \n",
    "}\n",
    "\n",
    "for file_path, text in sample_text.items():\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(text)\n",
    "\n",
    "print(\"Sample text files created successfully.\")\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "# can read text files and return a list of Document objects\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# can read all text files in a directory and return a list of Document objects - should be of time type .txt\n",
    "\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ") \n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
